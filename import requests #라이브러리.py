import requests
from bs4 import BeautifulSoup

# ë„¤ì´ë²„ ë‰´ìŠ¤ ì„¹ì…˜ URL (ì •ì¹˜ ë‰´ìŠ¤ ì˜ˆì‹œ)
url = "https://news.naver.com/section/100"

# 1. User-Agent ë° ì¶”ê°€ í—¤ë” ì„¤ì • (â­ì¶”ê°€ ì •ë³´ í¬í•¨â­)
headers = {
    # ê¸°ì¡´ User-AgentëŠ” ìœ ì§€
    'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36',
    
    # ğŸ’¡ ì¶”ê°€: ë¸Œë¼ìš°ì €ê°€ ì–´ë–¤ ì¢…ë¥˜ì˜ ì‘ë‹µì„ ì›í•˜ëŠ”ì§€ ëª…ì‹œ
    'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,image/avif,image/webp,image/apng,*/*;q=0.8,application/signed-exchange;v=b3;q=0.9',
    
    # ğŸ’¡ ì¶”ê°€: ë¸Œë¼ìš°ì € ì–¸ì–´ ì„¤ì • (í•œêµ­ì–´ë¡œ ì„¤ì •)
    'Accept-Language': 'ko-KR,ko;q=0.9,en-US;q=0.8,en;q=0.7',
    
    # ğŸ’¡ ì—°ê²°ì„ ëŠì§€ ì•Šê³  ê³„ì† ìœ ì§€í•˜ê² ë‹¤ëŠ” ì˜ë¯¸
    'Connection': 'keep-alive'
}

# 2. ì›¹í˜ì´ì§€ ìš”ì²­
response = requests.get(url, headers=headers) # ê°•í™”ëœ í—¤ë”ë¥¼ ì‚¬ìš©í•˜ì—¬ ìš”ì²­
response.raise_for_status() 
html = response.text

# 3. HTML íŒŒì‹±
soup = BeautifulSoup(html, "html.parser")

# 4. ë‰´ìŠ¤ ì œëª© ê°€ì ¸ì˜¤ê¸° (í´ë˜ìŠ¤ ì´ë¦„ì€ ê·¸ëŒ€ë¡œ ì‚¬ìš©)
titles = soup.find_all("a", class_="sa_item_title")

# 5. ê²°ê³¼ ì¶œë ¥
print("ğŸ“° ë„¤ì´ë²„ ë‰´ìŠ¤ ì„¹ì…˜ (ì •ì¹˜) ì œëª©ê³¼ ë§í¬ 10ê°œ")
print("---------------------------------------------")
if not titles:
    # ì œëª©ì´ ì¶”ì¶œë˜ì§€ ì•Šì•˜ì„ ê²½ìš° ì‚¬ìš©ìì—ê²Œ ì•Œë¦¼
    print("âš ï¸ ê²½ê³ : ì œëª©ì„ ì¶”ì¶œí•˜ì§€ ëª»í–ˆìŠµë‹ˆë‹¤. .")
else:
    for i, title_tag in enumerate(titles[:10], 1):
        title_text = title_tag.get_text().strip()
        link_url = title_tag.get('href')
        
        print(f"[{i}] {title_text}")
        print(f"    â¡ï¸ ë§í¬: {link_url}")
print("---------------------------------------------")